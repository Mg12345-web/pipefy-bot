const fs = require('fs');
const path = require('path');
const Tesseract = require('tesseract.js');
const { fromPath } = require('pdf2pic');
const { OpenAI } = require('openai');

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

// üß† GPT: interpreta um texto OCR com base no tipo de documento
async function interpretarTextoComGPT(textoOriginal, tipoDocumento = 'geral') {
  let systemPrompt = '';

  switch (tipoDocumento) {
    case 'procuracao':
      systemPrompt = 'Voc√™ √© um assistente que extrai dados de uma procura√ß√£o.';
      break;
    case 'crlv':
      systemPrompt = 'Voc√™ √© um assistente que extrai dados de um CRLV. Responda com JSON: placa, chassi, renavam, estadoEmplacamento.';
      break;
    case 'autuacao':
      systemPrompt = 'Voc√™ √© um assistente que extrai dados de uma notifica√ß√£o de autua√ß√£o. JSON: orgaoAutuador, numeroAIT, dataDefesaRecurso.';
      break;
    default:
      systemPrompt = 'Voc√™ √© um assistente que extrai dados de documentos de ve√≠culos e procura√ß√µes.';
  }

  try {
    const resposta = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: textoOriginal }
      ],
      temperature: 0.2
    });

    const content = resposta.choices[0].message.content;
    JSON.parse(content); // Valida o JSON
    return content;
  } catch (err) {
    console.error(`‚ùå Erro ao interpretar texto com GPT: ${err.message}`);
    return '{}';
  }
}

// üßæ OCR de imagem ou PDF (convertendo primeira p√°gina em imagem)
async function extractText(caminhoArquivo) {
  try {
    const extensao = path.extname(caminhoArquivo).toLowerCase();

    if (extensao === '.pdf') {
      const outputBase = path.join('/tmp', `ocr_${Date.now()}`);
      const converter = fromPath(caminhoArquivo, {
        density: 200,
        saveFilename: outputBase,
        savePath: '/tmp',
        format: 'png',
        width: 1200,
        height: 1600
      });

      const resultadoConversao = await converter(1); // p√°gina 1
      caminhoImagem = resultadoConversao.path;
    } else {
      caminhoImagem = caminhoArquivo; // j√° √© imagem
    }

    const resultado = await Tesseract.recognize(caminhoImagem, 'por', {
      logger: m => console.log(`[OCR] ${m.status}`)
    });

    return resultado.data.text;

  } catch (err) {
    console.error('‚ùå Erro no OCR:', err.message);
    return '';
  }
}

module.exports = {
  extractText,
  interpretarTextoComGPT
};
